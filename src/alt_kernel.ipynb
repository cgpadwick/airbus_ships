{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1629debb33bf38e7aec59f9352a8101a0bd9d627"
   },
   "source": [
    "V17: add TTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b0a8a3b377172743a038bab1a2b0037fded6dfc"
   },
   "source": [
    "# load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d5fde42cea10ed321db48bdbf98c2ff5bb631624"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.data import imread\n",
    "from skimage.morphology import label\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_dir = '/data2/cgp/airbus_ships/'\n",
    "train_img_dir = '/data2/cgp/airbus_ships/train/'\n",
    "test_img_dir = '/data2/cgp/airbus_ships/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca11fbb4762465b3f39fc57fe7b8ea03b8364239"
   },
   "source": [
    "# load train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a3c704fb07cdfcb1d8222c5c120ede71cfb40a9e"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_dir+'train_ship_segmentations_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a031f04ead0c80b2e89a66a2f02a2b69cb57e15e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e89c185d7cda1e9cf4aa994ccbff2d149301f315",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231723, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ab0c2f514ed221ce53a002d8d0dc2c5f7a5c4ea"
   },
   "source": [
    "# remove bug images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "09cd6e559b6b2579d2cea247d264965dc2b0b46f"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['ImageId'] != '6384c3e78.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1ee28ad6f073ed0f4b94da72c63d83b8be4e2765"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231722, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29fba13e2f013f979474f7a442050377a6594594"
   },
   "source": [
    "# remove 100000 non-ship images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2897043641266d32ece48820784acd7dd3fc1b53"
   },
   "outputs": [],
   "source": [
    "def area_isnull(x):\n",
    "    if x == x:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "bebad7619e6669ba992059d5e5ce050618353991"
   },
   "outputs": [],
   "source": [
    "train_df['isnan'] = train_df['EncodedPixels'].apply(area_isnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "1da4e42ed00a6672284ec11c35c01f12ae1cc2cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    149999\n",
       "0     81723\n",
       "Name: isnan, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isnan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "2fcfdcc32083d84aa16349e2b8161b11589a5fff"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values('isnan', ascending=False)\n",
    "train_df = train_df.iloc[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b77a9e8ccde826913db1b59e9c4442c8e659f5de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    81723\n",
       "1    49999\n",
       "Name: isnan, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isnan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7dd6933eff3da6c5cc252906ea0ba62a6a6dafde"
   },
   "source": [
    "# calculate ship area and group by ImageId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "ebf3be677dccbf2355796ddc36d296c7b63553d4"
   },
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_list, SHAPE):\n",
    "    tmp_flat = np.zeros(SHAPE[0]*SHAPE[1])\n",
    "    if len(rle_list) == 1:\n",
    "        mask = np.reshape(tmp_flat, SHAPE).T\n",
    "    else:\n",
    "        strt = rle_list[::2]\n",
    "        length = rle_list[1::2]\n",
    "        for i,v in zip(strt,length):\n",
    "            tmp_flat[(int(i)-1):(int(i)-1)+int(v)] = 255\n",
    "        mask = np.reshape(tmp_flat, SHAPE).T\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1631abfa59f902f8ba0c8d8ac0bb569839343f73"
   },
   "outputs": [],
   "source": [
    "def calc_area_for_rle(rle_str):\n",
    "    rle_list = [int(x) if x.isdigit() else x for x in str(rle_str).split()]\n",
    "    if len(rle_list) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        area = np.sum(rle_list[1::2])\n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "5ff2925d082443d18bc15d3db1926f51317c9d84",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['area'] = train_df['EncodedPixels'].apply(calc_area_for_rle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96d22e772c1a8a15ce4c029bb81f1457084db3bc"
   },
   "source": [
    "get small area of one ship; If estimated area of the ship is less than 10, it is corrected to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c58bd7fb393a46f3e8836ca5403176f35a5a580f"
   },
   "outputs": [],
   "source": [
    "train_df_isship = train_df[train_df['area'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "09220ce4808d0e3ad6ce5b8d06292e992851c080"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81723, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_isship.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "78ac5414ae6ae2e09ff71611faff6b068091a849"
   },
   "outputs": [],
   "source": [
    "train_df_smallarea = train_df_isship['area'][train_df_isship['area'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "4580043aab3643b8165ff84901aba7250f315f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_smallarea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "d5193177a2be8d075c90515f1617bc0fa38c5476"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001235882187389107"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_smallarea.shape[0]/train_df_isship.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "a86a48c0004a661d0c2500df5d204372a64e14e3"
   },
   "outputs": [],
   "source": [
    "train_gp = train_df.groupby('ImageId').sum()\n",
    "train_gp = train_gp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "79d82936f70a65e5a8e74adf1506c91d6d9d519f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>isnan</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002756f7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  isnan  area\n",
       "0  000155de5.jpg      0  3388\n",
       "1  000194a2d.jpg      0  1460\n",
       "2  0001b1832.jpg      1     0\n",
       "3  00021ddc3.jpg      0  1176\n",
       "4  0002756f7.jpg      0   408"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71f5b59a92997f5e8b41e833d2f06d32bdd6b076"
   },
   "source": [
    "# set class of ship area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2a34c342c77899db2965053a86a17f814332075f"
   },
   "outputs": [],
   "source": [
    "def calc_class(area):\n",
    "    area = area / (768*768)\n",
    "    if area == 0:\n",
    "        return 0\n",
    "    elif area < 0.005:\n",
    "        return 1\n",
    "    elif area < 0.015:\n",
    "        return 2\n",
    "    elif area < 0.025:\n",
    "        return 3\n",
    "    elif area < 0.035:\n",
    "        return 4\n",
    "    elif area < 0.045:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "83978353dab607e852973f2d20f1aaf33b6a1a56"
   },
   "outputs": [],
   "source": [
    "train_gp['class'] = train_gp['area'].apply(calc_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "e6b44bff8284f678684e808c816b9b317754cc3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49999\n",
       "1    29315\n",
       "2     9225\n",
       "3     2644\n",
       "4     1122\n",
       "5      181\n",
       "6       69\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gp['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f541afa0e92409130af76771cdb85e3fe4bcc80"
   },
   "source": [
    "# split train-set and validation-set (stratified: area class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "50ab7af05bcb118ce15f6d21e5b954c95b01b6ec"
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_gp, test_size=0.01, stratify=train_gp['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "041674775a2408dc377c3685804dd8ef68709c57"
   },
   "outputs": [],
   "source": [
    "train_isship_list = train['ImageId'][train['isnan']==0].tolist()\n",
    "train_isship_list = random.sample(train_isship_list, len(train_isship_list))\n",
    "train_nanship_list = train['ImageId'][train['isnan']==1].tolist()\n",
    "train_nanship_list = random.sample(train_nanship_list, len(train_nanship_list))\n",
    "\n",
    "val_isship_list = val['ImageId'][val['isnan']==0].tolist()\n",
    "val_nanship_list = val['ImageId'][val['isnan']==1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "b9fab1f00b65d54cbb0be5e0ec761461eda35109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42130, 49499)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_isship_list),len(train_nanship_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "460b800e8115caed87dc6d261d86e530482abae3"
   },
   "source": [
    "# create data generator\n",
    "Make the ratio of is-ship images and nan-ship images  equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "dbd3143b1cce5c089a5fcab70640aeb2f7f35917"
   },
   "outputs": [],
   "source": [
    "def mygenerator(isship_list, nanship_list, batch_size, cap_num):\n",
    "    train_img_names_nanship = isship_list[:cap_num]\n",
    "    train_img_names_isship = nanship_list[:cap_num]\n",
    "    k = 0\n",
    "    while True:\n",
    "        if k+batch_size//2 >= cap_num:\n",
    "            k = 0\n",
    "        batch_img_names_nan = train_img_names_nanship[k:k+batch_size//2]\n",
    "        batch_img_names_is = train_img_names_isship[k:k+batch_size//2]\n",
    "        batch_img = []\n",
    "        batch_mask = []\n",
    "        for name in batch_img_names_nan:\n",
    "            tmp_img = imread(train_img_dir + name)\n",
    "            batch_img.append(tmp_img)\n",
    "            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "            one_mask = np.zeros((768, 768, 1))\n",
    "            for item in mask_list:\n",
    "                rle_list = str(item).split()\n",
    "                tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "                one_mask[:,:,0] += tmp_mask\n",
    "            batch_mask.append(one_mask)\n",
    "        for name in batch_img_names_is:\n",
    "            tmp_img = imread(train_img_dir + name)\n",
    "            batch_img.append(tmp_img)\n",
    "            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "            one_mask = np.zeros((768, 768, 1))\n",
    "            for item in mask_list:\n",
    "                rle_list = str(item).split()\n",
    "                tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "                one_mask[:,:,0] += tmp_mask\n",
    "            batch_mask.append(one_mask)\n",
    "        img = np.stack(batch_img, axis=0)\n",
    "        mask = np.stack(batch_mask, axis=0)\n",
    "        img = img / 255.0\n",
    "        mask = mask / 255.0\n",
    "        k += batch_size//2\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "480a5e01e3350f83127b181ed90217c4bec0c7f2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "CAP_NUM = min(len(train_isship_list),len(train_nanship_list))\n",
    "datagen = mygenerator(train_isship_list, train_nanship_list, batch_size=BATCH_SIZE, cap_num=CAP_NUM)\n",
    "\n",
    "valgen = mygenerator(val_isship_list, val_nanship_list, batch_size=50, cap_num=CAP_NUM)\n",
    "\n",
    "numvalimages = 50\n",
    "val_x, val_y = next(valgen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "103ddaa8ffbfbf2a4c6a20e30e289b14519fa5bb"
   },
   "source": [
    "# set model\n",
    "U-net with Hypercolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "4b6b9487a40d3442c47d39d22693255bf4a5722f"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(768,768,3))\n",
    "conv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "conv0 = BatchNormalization()(conv0)\n",
    "conv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv0)\n",
    "conv0 = BatchNormalization()(conv0)\n",
    "\n",
    "comp0 = AveragePooling2D((6,6))(conv0)\n",
    "conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(comp0)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Dropout(0.4)(conv1)\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Dropout(0.4)(conv2)\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Dropout(0.4)(conv3)\n",
    "\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Dropout(0.4)(conv4)\n",
    "\n",
    "pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "upcv6 = UpSampling2D(size=(2,2))(conv5)\n",
    "upcv6 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv6)\n",
    "upcv6 = BatchNormalization()(upcv6)\n",
    "mrge6 = concatenate([conv4, upcv6], axis=3)\n",
    "conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "upcv7 = UpSampling2D(size=(2,2))(conv6)\n",
    "upcv7 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv7)\n",
    "upcv7 = BatchNormalization()(upcv7)\n",
    "mrge7 = concatenate([conv3, upcv7], axis=3)\n",
    "conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "upcv8 = UpSampling2D(size=(2,2))(conv7)\n",
    "upcv8 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv8)\n",
    "upcv8 = BatchNormalization()(upcv8)\n",
    "mrge8 = concatenate([conv2, upcv8], axis=3)\n",
    "conv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge8)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "conv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "upcv9 = UpSampling2D(size=(2,2))(conv8)\n",
    "upcv9 = Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv9)\n",
    "upcv9 = BatchNormalization()(upcv9)\n",
    "mrge9 = concatenate([conv1, upcv9], axis=3)\n",
    "conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "dcmp10 = UpSampling2D((6,6), interpolation='bilinear')(conv9)\n",
    "mrge10 = concatenate([dcmp10, conv0], axis=3)\n",
    "conv10 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge10)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "conv10 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "conv11 = Conv2D(1, 1, activation='sigmoid')(conv10)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=conv11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "72167df2bd5af4e2775b33606e0d50bf04b5aeee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 768, 768, 8)  224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 768, 768, 8)  32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 768, 768, 8)  584         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 768, 768, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 128, 128, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 16) 1168        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 16) 2320        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  131200      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 32)   8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 64)   0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 32) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 16) 2064        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 16) 64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 16) 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 768, 768, 16) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 768, 768, 24) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 768, 768, 16) 3472        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 768, 768, 16) 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 768, 768, 8)  1160        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 768, 768, 8)  32          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 768, 768, 1)  9           batch_normalization_26[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,954,265\n",
      "Trainable params: 1,950,761\n",
      "Non-trainable params: 3,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "b6e3ff01b8b1239816a99efe6bfcdee2d8ca11fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, TensorBoard, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math, shutil\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='loss', factor=0.7, \n",
    "                                   patience=10, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "\n",
    "if os.path.exists('./log'):\n",
    "    shutil.rmtree('./log')\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='./log', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [tb_callback, reduceLROnPlat]\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3, decay=0.0), loss=dice_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21ad2aaaca671e22521b7fd6e92763367dacf954"
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89db399ff1ae9b94d54db1f077fb5ef488c718a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 209s 837ms/step - loss: 0.4021 - val_loss: 0.3914\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.4063 - val_loss: 0.4597\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3753 - val_loss: 0.3961\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.4066 - val_loss: 0.4719\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 212s 849ms/step - loss: 0.4282 - val_loss: 0.4960\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.3916 - val_loss: 0.4354\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.3877 - val_loss: 0.4463\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 212s 849ms/step - loss: 0.3924 - val_loss: 0.4690\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 213s 853ms/step - loss: 0.4130 - val_loss: 0.4690\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.4192 - val_loss: 0.4692\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.4320 - val_loss: 0.4844\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.4227 - val_loss: 0.4002\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.3879 - val_loss: 0.4656\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.3878 - val_loss: 0.4731\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.4133 - val_loss: 0.6027\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 212s 846ms/step - loss: 0.3917 - val_loss: 0.5782\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.3871 - val_loss: 0.4748\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 212s 846ms/step - loss: 0.3945 - val_loss: 0.5049\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.4146 - val_loss: 0.5144\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 212s 848ms/step - loss: 0.4063 - val_loss: 0.4874\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3942 - val_loss: 0.4829\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.3837 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3848 - val_loss: 0.4393\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3800 - val_loss: 0.3985\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3723 - val_loss: 0.4147\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.3844 - val_loss: 0.4689\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.3969 - val_loss: 0.4484\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 212s 847ms/step - loss: 0.3997 - val_loss: 0.4867\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.4015 - val_loss: 0.4959\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.3704 - val_loss: 0.4753\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 211s 843ms/step - loss: 0.3651 - val_loss: 0.4215\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.3757 - val_loss: 0.4240\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 211s 843ms/step - loss: 0.3641 - val_loss: 0.4041\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.3793 - val_loss: 0.3969\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 210s 840ms/step - loss: 0.3734 - val_loss: 0.3814\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 211s 843ms/step - loss: 0.3606 - val_loss: 0.4371\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3704 - val_loss: 0.4124\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3639 - val_loss: 0.3928\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3574 - val_loss: 0.4101\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 210s 842ms/step - loss: 0.3519 - val_loss: 0.4059\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.3600 - val_loss: 0.3865\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3780 - val_loss: 0.4428\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3588 - val_loss: 0.4115\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 210s 842ms/step - loss: 0.3692 - val_loss: 0.4098\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3485 - val_loss: 0.4635\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.3679 - val_loss: 0.4512\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3619 - val_loss: 0.4429\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3669 - val_loss: 0.4386\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3609 - val_loss: 0.4212\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3541 - val_loss: 0.3748\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 210s 842ms/step - loss: 0.3487 - val_loss: 0.3681\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 210s 841ms/step - loss: 0.3532 - val_loss: 0.3952\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 210s 842ms/step - loss: 0.3515 - val_loss: 0.4642\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 211s 844ms/step - loss: 0.3520 - val_loss: 0.3928\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 212s 846ms/step - loss: 0.3504 - val_loss: 0.4513\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 212s 850ms/step - loss: 0.3401 - val_loss: 0.4639\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 215s 861ms/step - loss: 0.3536 - val_loss: 0.3900\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3474 - val_loss: 0.3805\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 211s 843ms/step - loss: 0.3333 - val_loss: 0.3847\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 212s 846ms/step - loss: 0.3319 - val_loss: 0.3521\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.3519 - val_loss: 0.4094\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 211s 845ms/step - loss: 0.3520 - val_loss: 0.3989\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 216s 864ms/step - loss: 0.3589 - val_loss: 0.4750\n",
      "Epoch 64/100\n",
      " 50/250 [=====>........................] - ETA: 2:54 - loss: 0.3561"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen, steps_per_epoch = 250, epochs = NUM_EPOCHS, callbacks=callbacks_list,\n",
    "                             validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch = np.cumsum(np.concatenate([np.linspace(0.5, 1, len(mh.epoch)) for mh in history]))\n",
    "#plt.plot(epoch, np.concatenate([mh.history['loss'] for mh in loss_history]), 'b-')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('seg_model_hypercolumn.json', 'w')\n",
    "#model.to_json('seg_model_hypercolumn.json')\n",
    "model.save('seg_model_hypercolumn.h5')\n",
    "#model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(tt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9995f4c4fa4f109e3f1a549a08a51264f3012572"
   },
   "source": [
    "# calculate F2 score for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68cfaff71251405f626de610723c87332a442d91"
   },
   "source": [
    "- set  function of caluculating  score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "042baa7e5568598511b37fcc1ffbd839d916524e"
   },
   "outputs": [],
   "source": [
    "def calc_IoU(A, B):\n",
    "    AorB = np.logical_or(A,B).astype('int')\n",
    "    AandB = np.logical_and(A,B).astype('int')\n",
    "    IoU = AandB.sum() / AorB.sum()\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "155186fcb13c9998d4c141e71c8f10bdfa6c147d"
   },
   "outputs": [],
   "source": [
    "def calc_IoU_vector(A, B):\n",
    "    score_vector = []\n",
    "    IoU = calc_IoU(A, B)\n",
    "    for threshold in np.arange(0.5,1,0.05):\n",
    "        score = int(IoU > threshold)\n",
    "        score_vector.append(score)\n",
    "    return score_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f56502efebd409b2eb34f2ccba96e07a6c6c7e6f"
   },
   "outputs": [],
   "source": [
    "def calc_IoU_tensor(masks_true, masks_pred):\n",
    "    true_mask_num = masks_true.shape[0]\n",
    "    pred_mask_num = masks_pred.shape[0]\n",
    "    score_tensor = np.zeros((true_mask_num, pred_mask_num, 10))\n",
    "    for true_i in range(true_mask_num):\n",
    "        for pred_i in range(pred_mask_num):\n",
    "            true_mask = masks_true[true_i]\n",
    "            pred_mask = masks_pred[pred_i]\n",
    "            score_vector = calc_IoU_vector(true_mask, pred_mask)\n",
    "            score_tensor[true_i,pred_i,:] = score_vector\n",
    "    return score_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec3b1975edaaebef7d2e73ff484a41a1f3eec397"
   },
   "outputs": [],
   "source": [
    "def calc_F2_per_one_threshold(score_matrix):\n",
    "    tp = np.sum( score_matrix.sum(axis=1) > 0  )\n",
    "    fp = np.sum( score_matrix.sum(axis=1) == 0 )\n",
    "    fn = np.sum( score_matrix.sum(axis=0) == 0 )\n",
    "    F2 = (5*tp) / ((5*tp) + fp + (4*fn))\n",
    "    return F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f9843b83986ac9abf159aa3972e5aa69aebb37c"
   },
   "outputs": [],
   "source": [
    "def calc_score_one_image(mask_true, mask_pred):\n",
    "    mask_true = mask_true.reshape(768,768)\n",
    "    mask_pred = mask_pred.reshape(768,768)\n",
    "    if mask_true.sum() == 0 and mask_pred.sum() == 0:\n",
    "        score = 1\n",
    "    elif mask_true.sum() == 0 and mask_pred.sum() != 0:\n",
    "        score = 0\n",
    "    elif mask_true.sum() != 0 and mask_pred.sum() == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        mask_label_true = label(mask_true)\n",
    "        mask_label_pred = label(mask_pred)\n",
    "        c_true = np.max(mask_label_true)\n",
    "        c_pred = np.max(mask_label_pred)\n",
    "        tmp = []\n",
    "        for k in range(c_true):\n",
    "            tmp.append(mask_label_true == k+1)\n",
    "        masks_true = np.stack(tmp, axis=0)\n",
    "        tmp = []\n",
    "        for k in range(c_pred):\n",
    "            tmp.append(mask_label_pred == k+1)\n",
    "        masks_pred = np.stack(tmp, axis=0)\n",
    "        score_tensor = calc_IoU_tensor(masks_true, masks_pred)\n",
    "        F2_t = []\n",
    "        for i in range(10):\n",
    "            F2 = calc_F2_per_one_threshold(score_tensor[:,:,i])\n",
    "            F2_t.append(F2)\n",
    "        score = np.mean(F2_t)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a36dac77afe53bfe329dbbe305767643f9a1e57f"
   },
   "outputs": [],
   "source": [
    "def calc_score_all_image(batch_mask_true, batch_mask_pred, threshold=0.5):\n",
    "    num = batch_mask_true.shape[0]\n",
    "    tmp = batch_mask_pred > threshold\n",
    "    batch_mask_pred = tmp.astype('int')\n",
    "    scores = list()\n",
    "    for i in range(num):\n",
    "        score = calc_score_one_image(batch_mask_true[i], batch_mask_pred[i])\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fda7b099099d639a512a111d4431c58c3f1a4788"
   },
   "source": [
    "- set validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993e4b6ef00a7c99af0e8a1c3c42122ff3cf832a"
   },
   "outputs": [],
   "source": [
    "val_list = val['ImageId'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac0b96a55b1c3f3407d66768473ddeef878489be"
   },
   "outputs": [],
   "source": [
    "def create_data(image_list):\n",
    "    batch_img = []\n",
    "    batch_mask = []\n",
    "    for name in image_list:\n",
    "        tmp_img = imread(train_img_dir + name)\n",
    "        batch_img.append(tmp_img)\n",
    "        mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "        one_mask = np.zeros((768, 768, 1))\n",
    "        for item in mask_list:\n",
    "            rle_list = str(item).split()\n",
    "            tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "            one_mask[:,:,0] += tmp_mask\n",
    "        batch_mask.append(one_mask)\n",
    "    img = np.stack(batch_img, axis=0)\n",
    "    mask = np.stack(batch_mask, axis=0)\n",
    "    img = img / 255.0\n",
    "    mask = mask / 255.0\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "16f578e4c9040d6f8ccf0b9805ef331e85443360"
   },
   "source": [
    "- put it together and search optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3231b850835ae2a14a76210a52181dbe169734d"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72951698b0a229289bea4d4b75d33c0e4472d1cd"
   },
   "outputs": [],
   "source": [
    "#search threshold\n",
    "scores_list = dict()\n",
    "threshold_list = [x/100 for x in range(20,80,10)]\n",
    "for threshold in threshold_list:\n",
    "    scores = []\n",
    "    for i in tqdm(range(len(val_list)//2)):\n",
    "        temp_list = val_list[i*2:(i+1)*2]\n",
    "        val_img, val_mask = create_data(temp_list)\n",
    "        pred_mask = model.predict(val_img)\n",
    "        F2 = calc_score_all_image(val_mask, pred_mask, threshold=threshold)*2\n",
    "        scores.append(F2)\n",
    "    val_F2 = np.sum(scores)/(len(val_list)//2 *2)\n",
    "    scores_list[threshold] = val_F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c189c29e0a3710c7c6c5dec04f781089ec29d7a8"
   },
   "outputs": [],
   "source": [
    "scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2ef157ba4aaa035be93065855bad3b4b91941f1"
   },
   "outputs": [],
   "source": [
    "opt_threshold = max(scores_list, key=scores_list.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44da6c465f5bb6f247e74d05d85e549e40c0c57a"
   },
   "source": [
    "# visualize predict images\n",
    "display 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60e827ad3090b8f64e1fd039c3c179914511615b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# generate validation image predictions\n",
    "from skimage.io import imsave\n",
    "val_dir = './val_images/'\n",
    "if not os.path.exists(val_dir):\n",
    "    os.rmdir(val_dir)\n",
    "    os.mkdir(val_dir)\n",
    "    \n",
    "for i in range(len(val_list)):\n",
    "    img_name = os.path.join(train_img_dir, val_list[i])\n",
    "    print(val_list[i])\n",
    "    img = imread(img_name)\n",
    "    input_img, gt_mask = create_data([val_list[i]])\n",
    "    pred_mask = model.predict(input_img)\n",
    "    pred_mask = pred_mask.reshape(768,768,1)\n",
    "    input_img = input_img.reshape(768, 768, 3)\n",
    "    input_img = (input_img * 255).astype(np.uint8)\n",
    "    gt_mask = gt_mask\n",
    "    gt_mask = gt_mask.reshape(768,768)\n",
    "    pred_mask = pred_mask.reshape(768,768)\n",
    "    base, ext = os.path.splitext(os.path.basename(img_name))\n",
    "    out_img = os.path.join(val_dir, os.path.basename(img_name))\n",
    "    imsave(out_img, input_img * 255)\n",
    "    out_gt_mask = os.path.join(val_dir, base + '_gt.png')\n",
    "    imsave(out_gt_mask, gt_mask)\n",
    "    out_pred_mask = os.path.join(val_dir, base + '_pred.png')\n",
    "    imsave(out_pred_mask, pred_mask)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a8350045f26f0f7c3edf0eeee3be7d06916aaf6"
   },
   "outputs": [],
   "source": [
    "image_list = val_list[20:30]\n",
    "fig, axes = plt.subplots(len(image_list), 3, figsize=(100,100))\n",
    "fig.subplots_adjust(left=0.075,right=0.95,bottom=0.05,top=0.52,wspace=0.2,hspace=0.10)\n",
    "for i in range(len(image_list)):\n",
    "    img = imread(train_img_dir + image_list[i])\n",
    "    input_img, gt_mask = create_data([image_list[i]])\n",
    "    pred_mask = model.predict(input_img)\n",
    "    pred_mask = pred_mask > opt_threshold\n",
    "    pred_mask = pred_mask.reshape(768,768,1)\n",
    "    gt_mask = gt_mask * 255\n",
    "    gt_mask = gt_mask.reshape(768,768)\n",
    "    pred_mask = pred_mask.reshape(768,768)\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 1].imshow(gt_mask)\n",
    "    axes[i, 2].imshow(pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "347084c09bb0c85401e796eb7f58f9e2e73b52ed"
   },
   "source": [
    "# predict test set and submission with Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c77b88803cd0ff553588acdf47ff3bf7dced6ec"
   },
   "outputs": [],
   "source": [
    "test_img_names = [x.split('.')[0] for x in os.listdir(test_img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe14489bb81d8c4aee7d8c2468105e48c8e13bad"
   },
   "outputs": [],
   "source": [
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels = label(img[0,:,:,:])\n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return '' ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return '' ## ignore overfilled mask\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "739de9efa942890b48985972a28432d26415ee07"
   },
   "outputs": [],
   "source": [
    "pred_rows = []\n",
    "for name in tqdm(test_img_names):\n",
    "    test_img = imread(test_img_dir + name + '.jpg')\n",
    "    test_img_1 = test_img.reshape(1,768,768,3)/255.0\n",
    "    test_img_2 = test_img_1[:, :, ::-1, :]\n",
    "    test_img_3 = test_img_1[:, ::-1, :, :]\n",
    "    test_img_4 = test_img_1[:, ::-1, ::-1, :]\n",
    "    pred_prob_1 = model.predict(test_img_1)\n",
    "    pred_prob_2 = model.predict(test_img_2)\n",
    "    pred_prob_3 = model.predict(test_img_3)\n",
    "    pred_prob_4 = model.predict(test_img_4)\n",
    "    pred_prob = (pred_prob_1 + pred_prob_2[:, :, ::-1, :] + pred_prob_3[:, ::-1, :, :] + pred_prob_4[:, ::-1, ::-1, :])/4\n",
    "    pred_mask = pred_prob > opt_threshold\n",
    "    rles = multi_rle_encode(pred_mask)\n",
    "    if len(rles)>0:\n",
    "        for rle in rles:\n",
    "            pred_rows += [{'ImageId': name + '.jpg', 'EncodedPixels': rle}]\n",
    "    else:\n",
    "        pred_rows += [{'ImageId': name + '.jpg', 'EncodedPixels': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8a40b3b7c50419be4e03f3ee3dec296977165aa"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(pred_rows)[['ImageId', 'EncodedPixels']]\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
